# Agent Conclave — example configuration
# Get a second AI opinion without being human middleware.
#
# Configure two or more models, assign roles, and let them debate.
# White smoke when they agree, black smoke when they don't.

models:
  cards:
    # Local models via Ollama (free, no API key)
    - id: cli:llama
      command: [ollama, run, llama3.2]
      prompt_mode: arg
      timeout_seconds: 120

    - id: cli:qwen
      command: [ollama, run, qwen2.5:7b]
      prompt_mode: arg
      timeout_seconds: 120

    # Uncomment to use hosted models instead:
    # - id: cli:claude
    #   command: [claude, --print, --model, sonnet, --output-format, text]
    #   prompt_mode: arg
    #   timeout_seconds: 300
    # - id: cli:codex
    #   command: [codex, exec, --ephemeral, --sandbox, read-only]
    #   prompt_mode: stdin
    #   stdin_flag: "-"
    #   timeout_seconds: 300

# Assign roles — who argues FOR, who argues AGAINST
planner:
  role_overrides:
    reasoner: cli:llama       # builds the case
    critic: cli:qwen          # tears it apart
    summarizer: cli:qwen      # synthesizes the verdict

# Deliberation settings
deliberation:
  max_rounds: 5               # max back-and-forth rounds
  stability_rounds: 2         # stop after 2 consecutive agreements
  model_timeout_seconds: 120  # per-model call timeout

  # Panel: optional tiebreaker when reasoner and critic disagree
  panel:
    enabled: false
    # model_ids: [cli:gemini]
    # include_plan_models: false
    # max_rounds: 1

# Simulated annealing — run N deliberations with decreasing randomness,
# keep the best. Great for subjective queries where you want diverse
# perspectives converging on an optimal answer.
annealing:
  enabled: false
  # max_iterations: 3              # number of deliberation runs
  # stable_rounds: 2               # stop early after N runs with no improvement
  # schedule: linear               # temperature decay: linear or exponential
  # temperature_start: 1.2         # initial randomness
  # temperature_end: 0.3           # final randomness
  # noise_start: 0.18              # initial planning noise
  # noise_end: 0.05                # final planning noise
  # perturb_prompt: true            # prepend a perspective-shift each run
  # perturbation_phrases:
  #   - "Consider contrarian viewpoints."
  #   - "Focus on practical constraints."
  #   - "Prioritize cost-effectiveness."
  #   - "Weight long-term outcomes heavily."
  #   - "Consider what could go wrong."
  # content_convergence: true       # detect when answers stabilize
  # similarity_threshold: 0.85      # how similar = "converged"

diversity_check:
  enabled: false
